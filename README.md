# Introduction

CS224N 스터디의 학습내용 정리와 issue공유를 위한 repo입니다. 

[강의 링크](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/)

# Participant (alphabetical order)

| 이름 | repo |
| :---: | :---: |
|유인혁|[https://github.com/InhyeokYoo](https://github.com/InhyeokYoo) |
|장건희| |
|최슬기| |




# 기록 (10.15.20 - )

## Week 1 (10.13.20)

### 1. Introduction and Word Vectors, 유인혁 (10.15.20)

### 2. Word Vectors 2 and Word Senses, 유인혁 (10.15.20)

## Week 2 (10.21.20)

### 3. Word Window Classification, Neural Networks, and Matrix Calculus

### 4. Backpropagation and Computation Graphs

### 5. Linguistic Structure: Dependency Parsing

### 6. The probability of a sentence? Recurrent Neural Networks and Language Models 

### 7. Vanishing Gradients and Fancy RNNs

### 8. Machine Translation, Seq2Seq and Attention 

### 9. Practical Tips for Final Projects 

### 10. Question Answering and the Default Final Project

### 11. ConvNets for NLP 

### 12. Information from parts of words: Subword Models 

### 13. Modeling contexts of use: Contextual Representations and Pretraining 

### 14. Transformers and Self-Attention For Generative Models

### 15. Natural Language Generation 

### 16. Reference in Language and Coreference Resolution

### 17. Multitask Learning: A general model for NLP?

### 18. Constituency Parsing and Tree Recursive Neural Networks 

### 19. Future of NLP + Deep Learning 


